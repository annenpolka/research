"""
AutoPromptã‚’ä½¿ç”¨ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã®ä¾‹

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’
AutoPromptãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ã£ã¦è‡ªå‹•çš„ã«æ”¹å–„ã—ã¾ã™ã€‚

å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
pip install auto-prompt langchain-anthropic
"""

from auto_prompt import PromptOptimizer
from langchain_anthropic import ChatAnthropic
from typing import List, Dict

# ===========================
# 1. åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
# ===========================

INITIAL_PROMPT = """ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†æã—ã€ä¸é©åˆ‡ãªè¦ç´ ãŒã‚ã‚Œã°ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

åˆ†é¡ã‚«ãƒ†ã‚´ãƒª:
- safe: å•é¡Œãªã—
- hate_speech: ãƒ˜ã‚¤ãƒˆã‚¹ãƒ”ãƒ¼ãƒã‚„å·®åˆ¥çš„è¡¨ç¾
- violence: æš´åŠ›çš„ãªè¡¨ç¾
- sexual: æ€§çš„ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„
- spam: ã‚¹ãƒ‘ãƒ ã‚„è©æ¬º

ã‚³ãƒ³ãƒ†ãƒ³ãƒ„: {content}

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{"category": "åˆ†é¡çµæœ", "confidence": 0.0-1.0, "reason": "åˆ¤æ–­ç†ç”±"}}
"""


# ===========================
# 2. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
# ===========================

def create_training_samples() -> List[Dict]:
    """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿"""

    return [
        # Safe examples
        {
            "content": "ã“ã®è£½å“ã¯æœ¬å½“ã«ç´ æ™´ã‚‰ã—ã„ã§ã™ã€‚ãŠã™ã™ã‚ã—ã¾ã™ï¼",
            "label": "safe",
            "confidence": 0.95,
        },
        {
            "content": "ä»Šæ—¥ã¯å¤©æ°—ãŒè‰¯ã„ã§ã™ã­ã€‚æ•£æ­©ã«è¡Œãã¾ã—ã‚‡ã†ã€‚",
            "label": "safe",
            "confidence": 0.99,
        },
        # Spam examples
        {
            "content": "ä»Šã™ãã‚¯ãƒªãƒƒã‚¯ï¼100ä¸‡å††ãŒå½“ãŸã‚‹ãƒãƒ£ãƒ³ã‚¹ï¼ï¼ï¼",
            "label": "spam",
            "confidence": 0.90,
        },
        {
            "content": "ğŸ‰ç„¡æ–™ã§ç¨¼ã’ã¾ã™ğŸ‰ LINEã«ç™»éŒ²ã™ã‚‹ã ã‘ğŸ’°",
            "label": "spam",
            "confidence": 0.85,
        },
        # Hate speech examples
        {
            "content": "ã‚ã®æ°‘æ—ã¯åŠ£ã£ã¦ã„ã‚‹ã€‚è¿½ã„å‡ºã™ã¹ãã ã€‚",
            "label": "hate_speech",
            "confidence": 0.98,
        },
        # Violence examples
        {
            "content": "æš´åŠ›ã§è§£æ±ºã—ã‚ˆã†ã€‚æ®´ã£ã¦ã‚„ã‚‹ã€‚",
            "label": "violence",
            "confidence": 0.92,
        },
        # Sexual examples
        {
            "content": "18æ­³æœªæº€é–²è¦§ç¦æ­¢ [éœ²éª¨ãªæ€§çš„æå†™]",
            "label": "sexual",
            "confidence": 0.88,
        },
        # Edge cases (é›£ã—ã„ä¾‹)
        {
            "content": "ã“ã®æ˜ ç”»ã«ã¯æš´åŠ›ã‚·ãƒ¼ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚R15æŒ‡å®šã§ã™ã€‚",
            "label": "safe",  # æƒ…å ±æä¾›ãªã®ã§å®‰å…¨
            "confidence": 0.70,
        },
        {
            "content": "å½¼ã¯ç§ã‚’æ†ã‚“ã§ã„ã‚‹ã‚ˆã†ã§ã™ã€‚æ‚²ã—ã„ã§ã™ã€‚",
            "label": "safe",  # æ„Ÿæƒ…è¡¨ç¾ãªã®ã§å®‰å…¨
            "confidence": 0.75,
        },
        {
            "content": "æœŸé–“é™å®šã‚»ãƒ¼ãƒ«é–‹å‚¬ä¸­ï¼æœ€å¤§50%ã‚ªãƒ•",
            "label": "safe",  # æ­£å½“ãªåºƒå‘Š
            "confidence": 0.80,
        },
    ]


# ===========================
# 3. è©•ä¾¡é–¢æ•°
# ===========================

def evaluate_prediction(sample: Dict, prediction: str) -> float:
    """
    äºˆæ¸¬çµæœã‚’è©•ä¾¡

    Args:
        sample: æœŸå¾…ã•ã‚Œã‚‹ãƒ©ãƒ™ãƒ«æƒ…å ±
        prediction: ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœ

    Returns:
        ã‚¹ã‚³ã‚¢ (0.0 - 1.0)
    """
    import json

    try:
        pred_data = json.loads(prediction)
        predicted_category = pred_data.get("category", "").lower()
        expected_category = sample["label"].lower()

        # å®Œå…¨ä¸€è‡´
        if predicted_category == expected_category:
            return 1.0

        # éƒ¨åˆ†ä¸€è‡´ï¼ˆsafe vs ãã‚Œä»¥å¤–ã®åŒºåˆ¥ãŒæ­£ã—ã„ã‹ï¼‰
        expected_is_safe = expected_category == "safe"
        predicted_is_safe = predicted_category == "safe"

        if expected_is_safe == predicted_is_safe:
            return 0.5  # æ–¹å‘æ€§ã¯åˆã£ã¦ã„ã‚‹ãŒåˆ†é¡ãŒé•ã†

        return 0.0  # å®Œå…¨ã«é–“é•ã„

    except (json.JSONDecodeError, KeyError):
        return 0.0  # ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼


# ===========================
# 4. æœ€é©åŒ–å®Ÿè¡Œ
# ===========================

def optimize_moderation_prompt():
    """ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æœ€é©åŒ–"""

    print("=" * 70)
    print("AutoPrompt: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–")
    print("=" * 70)

    # LLMãƒ¢ãƒ‡ãƒ«è¨­å®š
    llm = ChatAnthropic(model="claude-sonnet-4.5", temperature=0.0)

    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼è¨­å®š
    optimizer = PromptOptimizer(
        llm=llm,
        task_description="""
        ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã€‚
        ãƒ¦ãƒ¼ã‚¶ãƒ¼æŠ•ç¨¿ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’5ã¤ã®ã‚«ãƒ†ã‚´ãƒªï¼ˆsafe, hate_speech, violence, sexual, spamï¼‰
        ã«åˆ†é¡ã—ã¾ã™ã€‚ç‰¹ã«ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ï¼ˆå¢ƒç•Œçš„ãªä¾‹ï¼‰ã§é«˜ç²¾åº¦ãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚
        """,
        initial_prompt=INITIAL_PROMPT,
        max_iterations=10,  # æœ€é©åŒ–ã®åå¾©å›æ•°
        budget_usd=1.0,  # æœ€å¤§ã‚³ã‚¹ãƒˆ
    )

    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«
    samples = create_training_samples()
    print(f"\nâœ“ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«: {len(samples)}ä»¶")

    # æœ€é©åŒ–å‰ã®è©•ä¾¡
    print("\n--- æœ€é©åŒ–å‰ã®è©•ä¾¡ ---")
    initial_scores = []

    for sample in samples[:5]:  # æœ€åˆã®5ã¤ã§è©•ä¾¡
        prompt = INITIAL_PROMPT.format(content=sample["content"])
        response = llm.predict(prompt)

        score = evaluate_prediction(sample, response)
        initial_scores.append(score)

        print(f"\nã‚³ãƒ³ãƒ†ãƒ³ãƒ„: {sample['content'][:50]}...")
        print(f"æœŸå¾…: {sample['label']}")
        print(f"äºˆæ¸¬: {response[:100]}...")
        print(f"ã‚¹ã‚³ã‚¢: {score:.2f}")

    avg_initial_score = sum(initial_scores) / len(initial_scores)
    print(f"\nå¹³å‡ã‚¹ã‚³ã‚¢ï¼ˆæœ€é©åŒ–å‰ï¼‰: {avg_initial_score:.2%}")

    # æœ€é©åŒ–å®Ÿè¡Œ
    print("\n--- æœ€é©åŒ–å®Ÿè¡Œä¸­ ---")
    print("(å¢ƒç•Œã‚±ãƒ¼ã‚¹ã®ç”Ÿæˆã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã‚’ç¹°ã‚Šè¿”ã—ã¾ã™)")

    result = optimizer.optimize(
        samples=samples, evaluation_fn=evaluate_prediction, verbose=True
    )

    # çµæœè¡¨ç¤º
    print("\n" + "=" * 70)
    print("æœ€é©åŒ–å®Œäº†ï¼")
    print("=" * 70)

    print(f"\nã€æ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‘")
    print("-" * 70)
    print(result.optimized_prompt)
    print("-" * 70)

    print(f"\nã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã€‘")
    print(f"æœ€é©åŒ–å‰ã®ç²¾åº¦: {result.initial_accuracy:.2%}")
    print(f"æœ€é©åŒ–å¾Œã®ç²¾åº¦: {result.final_accuracy:.2%}")
    improvement = (
        (result.final_accuracy - result.initial_accuracy) / result.initial_accuracy
    ) * 100
    print(f"æ”¹å–„ç‡: {improvement:+.1f}%")

    print(f"\nã€ã‚³ã‚¹ãƒˆã€‘")
    print(f"åˆè¨ˆã‚³ã‚¹ãƒˆ: ${result.total_cost:.2f}")
    print(f"åå¾©å›æ•°: {result.iterations}")

    print(f"\nã€ç”Ÿæˆã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‘")
    print(f"æŒ‘æˆ¦çš„ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: {len(result.benchmark_dataset)}ä»¶")
    for i, case in enumerate(result.benchmark_dataset[:3], 1):
        print(f"  {i}. {case['content'][:60]}...")

    return result


# ===========================
# 5. ä½¿ç”¨ä¾‹
# ===========================

def demo_optimized_prompt(optimized_prompt: str):
    """æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½¿ç”¨ä¾‹"""

    print("\n\n" + "=" * 70)
    print("æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½¿ç”¨ä¾‹")
    print("=" * 70)

    llm = ChatAnthropic(model="claude-sonnet-4.5", temperature=0.0)

    test_cases = [
        "ã‚ãªãŸã¯ç´ æ™´ã‚‰ã—ã„äººã§ã™ã­ï¼",
        "ä»Šã™ãç™»éŒ²ã§1å„„å††ğŸ’° ã‚¯ãƒªãƒƒã‚¯ğŸ‘†",
        "ç‰¹å®šã®äººç¨®ã‚’æ”»æ’ƒã™ã‚‹å†…å®¹...",
        "æ­´å²ã®æˆæ¥­ã§æˆ¦äº‰ã«ã¤ã„ã¦å­¦ã³ã¾ã—ãŸã€‚",
    ]

    for i, content in enumerate(test_cases, 1):
        print(f"\nã€ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}ã€‘")
        print(f"ã‚³ãƒ³ãƒ†ãƒ³ãƒ„: {content}")

        prompt = optimized_prompt.format(content=content)
        response = llm.predict(prompt)

        print(f"åˆ¤å®šçµæœ: {response}")
        print("-" * 70)


# ===========================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ===========================

if __name__ == "__main__":
    # æœ€é©åŒ–å®Ÿè¡Œ
    result = optimize_moderation_prompt()

    # ãƒ‡ãƒ¢
    demo_optimized_prompt(result.optimized_prompt)

    # ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    with open("optimized_moderation_prompt.txt", "w", encoding="utf-8") as f:
        f.write(result.optimized_prompt)

    print("\nâœ“ æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ 'optimized_moderation_prompt.txt' ã«ä¿å­˜ã—ã¾ã—ãŸ")
